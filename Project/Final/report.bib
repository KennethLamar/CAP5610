
% Journals

% First the Full Name is given, then the abbreviation used in the AMS Math
% Reviews, with an indication if it could not be found there.
% Note the 2nd overwrites the 1st, so swap them if you want the full name.

 %{AMS}
 @String{AMSTrans = "American Mathematical Society Translations" }
 @String{AMSTrans = "Amer. Math. Soc. Transl." }
 @String{BullAMS = "Bulletin of the American Mathematical Society" }
 @String{BullAMS = "Bull. Amer. Math. Soc." }
 @String{ProcAMS = "Proceedings of the American Mathematical Society" }
 @String{ProcAMS = "Proc. Amer. Math. Soc." }
 @String{TransAMS = "Transactions of the American Mathematical Society" }
 @String{TransAMS = "Trans. Amer. Math. Soc." }

 %ACM
 @String{CACM = "Communications of the {ACM}" }
 @String{CACM = "Commun. {ACM}" }
 @String{CompServ = "Comput. Surveys" }
 @String{JACM = "J. ACM" }
 @String{ACMMathSoft = "{ACM} Transactions on Mathematical Software" }
 @String{ACMMathSoft = "{ACM} Trans. Math. Software" }
 @String{SIGNUM = "{ACM} {SIGNUM} Newsletter" }
 @String{SIGNUM = "{ACM} {SIGNUM} Newslett." }

 @String{AmerSocio = "American Journal of Sociology" }
 @String{AmerStatAssoc = "Journal of the American Statistical Association" }
 @String{AmerStatAssoc = "J. Amer. Statist. Assoc." }
 @String{ApplMathComp = "Applied Mathematics and Computation" }
 @String{ApplMathComp = "Appl. Math. Comput." }
 @String{AmerMathMonthly = "American Mathematical Monthly" }
 @String{AmerMathMonthly = "Amer. Math. Monthly" }
 @String{BIT = "{BIT}" }
 @String{BritStatPsych = "British Journal of Mathematical and Statistical
          Psychology" }
 @String{BritStatPsych = "Brit. J. Math. Statist. Psych." }
 @String{CanMathBull = "Canadian Mathematical Bulletin" }
 @String{CanMathBull = "Canad. Math. Bull." }
 @String{CompApplMath = "Journal of Computational and Applied Mathematics" }
 @String{CompApplMath = "J. Comput. Appl. Math." }
 @String{CompPhys = "Journal of Computational Physics" }
 @String{CompPhys = "J. Comput. Phys." }
 @String{CompStruct = "Computers and Structures" }
 @String{CompStruct = "Comput. \& Structures" }
 @String{CompJour = "The Computer Journal" }
 @String{CompJour = "Comput. J." }
 @String{CompSysSci = "Journal of Computer and System Sciences" }
 @String{CompSysSci = "J. Comput. System Sci." }
 @String{Computing = "Computing" }
 @String{ContempMath = "Contemporary Mathematics" }
 @String{ContempMath = "Contemp. Math." }
 @String{Crelle = "Crelle's Journal" }
 @String{GiornaleMath = "Giornale di Mathematiche" }
 @String{GiornaleMath = "Giorn. Mat." } % didn't find in AMS MR., ibid.

 %IEEE
 @String{Computer = "{IEEE} Computer" }
 @String{IEEETransComp = "{IEEE} Transactions on Computers" }
 @String{IEEETransComp = "{IEEE} Trans. Comput." }
 @String{IEEETransAC = "{IEEE} Transactions on Automatic Control" }
 @String{IEEETransAC = "{IEEE} Trans. Automat. Control" }
 @String{IEEESpec = "{IEEE} Spectrum" } % didn't find in AMS MR
 @String{ProcIEEE = "Proceedings of the {IEEE}" }
 @String{ProcIEEE = "Proc. {IEEE}" } % didn't find in AMS MR
 @String{IEEETransAeroElec = "{IEEE} Transactions on Aerospace and Electronic
     Systems" }
 @String{IEEETransAeroElec = "{IEEE} Trans. Aerospace Electron. Systems" }

 @String{IMANumerAna = "{IMA} Journal of Numerical Analysis" }
 @String{IMANumerAna = "{IMA} J. Numer. Anal." }
 @String{InfProcLet = "Information Processing Letters" }
 @String{InfProcLet = "Inform. Process. Lett." }
 @String{InstMathApp = "Journal of the Institute of Mathematics and
     its Applications" }
 @String{InstMathApp = "J. Inst. Math. Appl." }
 @String{IntControl = "International Journal of Control" }
 @String{IntControl = "Internat. J. Control" }
 @String{IntNumerEng = "International Journal for Numerical Methods in
     Engineering" }
 @String{IntNumerEng = "Internat. J. Numer. Methods Engrg." }
 @String{IntSuper = "International Journal of Supercomputing Applications" }
 @String{IntSuper = "Internat. J. Supercomputing Applic." } % didn't find
%% in AMS MR
 @String{Kibernetika = "Kibernetika" }
 @String{JResNatBurStand = "Journal of Research of the National Bureau
     of Standards" }
 @String{JResNatBurStand = "J. Res. Nat. Bur. Standards" }
 @String{LinAlgApp = "Linear Algebra and its Applications" }
 @String{LinAlgApp = "Linear Algebra Appl." }
 @String{MathAnaAppl = "Journal of Mathematical Analysis and Applications" }
 @String{MathAnaAppl = "J. Math. Anal. Appl." }
 @String{MathAnnalen = "Mathematische Annalen" }
 @String{MathAnnalen = "Math. Ann." }
 @String{MathPhys = "Journal of Mathematical Physics" }
 @String{MathPhys = "J. Math. Phys." }
 @String{MathComp = "Mathematics of Computation" }
 @String{MathComp = "Math. Comp." }
 @String{MathScand = "Mathematica Scandinavica" }
 @String{MathScand = "Math. Scand." }
 @String{TablesAidsComp = "Mathematical Tables and Other Aids to Computation" }
 @String{TablesAidsComp = "Math. Tables Aids Comput." }
 @String{NumerMath = "Numerische Mathematik" }
 @String{NumerMath = "Numer. Math." }
 @String{PacificMath = "Pacific Journal of Mathematics" }
 @String{PacificMath = "Pacific J. Math." }
 @String{ParDistComp = "Journal of Parallel and Distributed Computing" }
 @String{ParDistComp = "J. Parallel and Distrib. Comput." } % didn't find
%% in AMS MR
 @String{ParComputing = "Parallel Computing" }
 @String{ParComputing = "Parallel Comput." }
 @String{PhilMag = "Philosophical Magazine" }
 @String{PhilMag = "Philos. Mag." }
 @String{ProcNAS = "Proceedings of the National Academy of Sciences
                    of the USA" }
 @String{ProcNAS = "Proc. Nat. Acad. Sci. U. S. A." }
 @String{Psychometrika = "Psychometrika" }
 @String{QuartMath = "Quarterly Journal of Mathematics, Oxford, Series (2)" }
 @String{QuartMath = "Quart. J. Math. Oxford Ser. (2)" }
 @String{QuartApplMath = "Quarterly of Applied Mathematics" }
 @String{QuartApplMath = "Quart. Appl. Math." }
 @String{RevueInstStat = "Review of the International Statisical Institute" }
 @String{RevueInstStat = "Rev. Inst. Internat. Statist." }

 %SIAM
 @String{JSIAM = "Journal of the Society for Industrial and Applied
     Mathematics" }
 @String{JSIAM = "J. Soc. Indust. Appl. Math." }
 @String{JSIAMB = "Journal of the Society for Industrial and Applied
     Mathematics, Series B, Numerical Analysis" }
 @String{JSIAMB = "J. Soc. Indust. Appl. Math. Ser. B Numer. Anal." }
 @String{SIAMAlgMeth = "{SIAM} Journal on Algebraic and Discrete Methods" }
 @String{SIAMAlgMeth = "{SIAM} J. Algebraic Discrete Methods" }
 @String{SIAMAppMath = "{SIAM} Journal on Applied Mathematics" }
 @String{SIAMAppMath = "{SIAM} J. Appl. Math." }
 @String{SIAMComp = "{SIAM} Journal on Computing" }
 @String{SIAMComp = "{SIAM} J. Comput." }
 @String{SIAMMatrix = "{SIAM} Journal on Matrix Analysis and Applications" }
 @String{SIAMMatrix = "{SIAM} J. Matrix Anal. Appl." }
 @String{SIAMNumAnal = "{SIAM} Journal on Numerical Analysis" }
 @String{SIAMNumAnal = "{SIAM} J. Numer. Anal." }
 @String{SIAMReview = "{SIAM} Review" }
 @String{SIAMReview = "{SIAM} Rev." }
 @String{SIAMSciStat = "{SIAM} Journal on Scientific and Statistical
     Computing" }
 @String{SIAMSciStat = "{SIAM} J. Sci. Statist. Comput." }

 @String{SoftPracExp = "Software Practice and Experience" }
 @String{SoftPracExp = "Software Prac. Experience" } % didn't find in AMS MR
 @String{StatScience = "Statistical Science" }
 @String{StatScience = "Statist. Sci." }
 @String{Techno = "Technometrics" }
 @String{USSRCompMathPhys = "{USSR} Computational Mathematics and Mathematical
     Physics" }
 @String{USSRCompMathPhys = "{U. S. S. R.} Comput. Math. and Math. Phys." }
 @String{VLSICompSys = "Journal of {VLSI} and Computer Systems" }
 @String{VLSICompSys = "J. {VLSI} Comput. Syst." }
 @String{ZAngewMathMech = "Zeitschrift fur Angewandte Mathematik und
     Mechanik" }
 @String{ZAngewMathMech = "Z. Angew. Math. Mech." }
 @String{ZAngewMathPhys = "Zeitschrift fur Angewandte Mathematik und Physik" }
 @String{ZAngewMathPhys = "Z. Angew. Math. Phys." }

% Publishers % ================================================= |

 @String{Academic = "Academic Press" }
 @String{ACMPress = "{ACM} Press" }
 @String{AdamHilger = "Adam Hilger" }
 @String{AddisonWesley = "Addison-Wesley" }
 @String{AllynBacon = "Allyn and Bacon" }
 @String{AMS = "American Mathematical Society" }
 @String{Birkhauser = "Birkha{\"u}ser" }
 @String{CambridgePress = "Cambridge University Press" }
 @String{Chelsea = "Chelsea" }
 @String{ClaredonPress = "Claredon Press" }
 @String{DoverPub = "Dover Publications" }
 @String{Eyolles = "Eyolles" }
 @String{HoltRinehartWinston = "Holt, Rinehart and Winston" }
 @String{Interscience = "Interscience" }
 @String{JohnsHopkinsPress = "The Johns Hopkins University Press" }
 @String{JohnWileySons = "John Wiley and Sons" }
 @String{Macmillan = "Macmillan" }
 @String{MathWorks = "The Math Works Inc." }
 @String{McGrawHill = "McGraw-Hill" }
 @String{NatBurStd = "National Bureau of Standards" }
 @String{NorthHolland = "North-Holland" }
 @String{OxfordPress = "Oxford University Press" }  %address Oxford or London?
 @String{PergamonPress = "Pergamon Press" }
 @String{PlenumPress = "Plenum Press" }
 @String{PrenticeHall = "Prentice-Hall" }
 @String{SIAMPub = "{SIAM} Publications" }
 @String{Springer = "Springer-Verlag" }
 @String{TexasPress = "University of Texas Press" }
 @String{VanNostrand = "Van Nostrand" }
 @String{WHFreeman = "W. H. Freeman and Co." }
 
% Prevent dashes for repeated names.
@IEEEtranBSTCTL{IEEEexample:BSTcontrol,
 CTLdash_repeated_names = "no"
}

%Entries

@InProceedings{SLURM,
author="Yoo, Andy B.
and Jette, Morris A.
and Grondona, Mark",
editor="Feitelson, Dror
and Rudolph, Larry
and Schwiegelshohn, Uwe",
title="SLURM: Simple Linux Utility for Resource Management",
booktitle="Job Scheduling Strategies for Parallel Processing",
year="2003",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="44--60",
abstract="A new cluster resource management system called Simple Linux Utility Resource Management (SLURM) is described in this paper. SLURM, initially developed for large Linux clusters at the Lawrence Livermore National Laboratory (LLNL), is a simple cluster manager that can scale to thousands of processors. SLURM is designed to be flexible and fault-tolerant and can be ported to other clusters of different size and architecture with minimal effort. We are certain that SLURM will benefit both users and system architects by providing them with a simple, robust, and highly scalable parallel job execution environment for their cluster system.",
isbn="978-3-540-39727-4"
}

@article{survey,
title = {Algorithm runtime prediction: Methods \& evaluation},
journal = {Artificial Intelligence},
volume = {206},
pages = {79-111},
year = {2014},
issn = {0004-3702},
doi = {https://doi.org/10.1016/j.artint.2013.10.003},
url = {https://www.sciencedirect.com/science/article/pii/S0004370213001082},
author = {Frank Hutter and Lin Xu and Holger H. Hoos and Kevin Leyton-Brown},
keywords = {Supervised machine learning, Performance prediction, Empirical performance models, Response surface models, Highly parameterized algorithms, Propositional satisfiability, Mixed integer programming, Travelling salesperson problem},
abstract = {Perhaps surprisingly, it is possible to predict how long an algorithm will take to run on a previously unseen input, using machine learning techniques to build a model of the algorithmʼs runtime as a function of problem-specific instance features. Such models have important applications to algorithm analysis, portfolio-based algorithm selection, and the automatic configuration of parameterized algorithms. Over the past decade, a wide variety of techniques have been studied for building such models. Here, we describe extensions and improvements of existing models, new families of models, and—perhaps most importantly—a much more thorough treatment of algorithm parameters as model inputs. We also comprehensively describe new and existing features for predicting algorithm runtime for propositional satisfiability (SAT), travelling salesperson (TSP) and mixed integer programming (MIP) problems. We evaluate these innovations through the largest empirical analysis of its kind, comparing to a wide range of runtime modelling techniques from the literature. Our experiments consider 11 algorithms and 35 instance distributions; they also span a very wide range of SAT, MIP, and TSP instances, with the least structured having been generated uniformly at random and the most structured having emerged from real industrial applications. Overall, we demonstrate that our new models yield substantially better runtime predictions than previous approaches in terms of their generalization to new problem instances, to new algorithms from a parameterized space, and to both simultaneously.}
}

@article{LAAMPS,
title = {LAMMPS - a flexible simulation tool for particle-based materials modeling at the atomic, meso, and continuum scales},
journal = {Computer Physics Communications},
volume = {271},
pages = {108171},
year = {2022},
issn = {0010-4655},
doi = {https://doi.org/10.1016/j.cpc.2021.108171},
url = {https://www.sciencedirect.com/science/article/pii/S0010465521002836},
author = {Aidan P. Thompson and H. Metin Aktulga and Richard Berger and Dan S. Bolintineanu and W. Michael Brown and Paul S. Crozier and Pieter J. {in 't Veld} and Axel Kohlmeyer and Stan G. Moore and Trung Dac Nguyen and Ray Shan and Mark J. Stevens and Julien Tranchida and Christian Trott and Steven J. Plimpton},
keywords = {Molecular dynamics, Materials modeling, Parallel algorithms, LAMMPS},
abstract = {Since the classical molecular dynamics simulator LAMMPS was released as an open source code in 2004, it has become a widely-used tool for particle-based modeling of materials at length scales ranging from atomic to mesoscale to continuum. Reasons for its popularity are that it provides a wide variety of particle interaction models for different materials, that it runs on any platform from a single CPU core to the largest supercomputers with accelerators, and that it gives users control over simulation details, either via the input script or by adding code for new interatomic potentials, constraints, diagnostics, or other features needed for their models. As a result, hundreds of people have contributed new capabilities to LAMMPS and it has grown from fifty thousand lines of code in 2004 to a million lines today. In this paper several of the fundamental algorithms used in LAMMPS are described along with the design strategies which have made it flexible for both users and developers. We also highlight some capabilities recently added to the code which were enabled by this flexibility, including dynamic load balancing, on-the-fly visualization, magnetic spin dynamics models, and quantum-accuracy machine learning interatomic potentials.
Program Summary
Program Title: Large-scale Atomic/Molecular Massively Parallel Simulator (LAMMPS) CPC Library link to program files: https://doi.org/10.17632/cxbxs9btsv.1 Developer's repository link: https://github.com/lammps/lammps Licensing provisions: GPLv2 Programming language: C++, Python, C, Fortran Supplementary material: https://www.lammps.org Nature of problem: Many science applications in physics, chemistry, materials science, and related fields require parallel, scalable, and efficient generation of long, stable classical particle dynamics trajectories. Within this common problem definition, there lies a great diversity of use cases, distinguished by different particle interaction models, external constraints, as well as timescales and lengthscales ranging from atomic to mesoscale to macroscopic. Solution method: The LAMMPS code uses parallel spatial decomposition, distributed neighbor lists, and parallel FFTs for long-range Coulombic interactions [1]. The time integration algorithm is based on the Størmer-Verlet symplectic integrator [2], which provides better stability than higher-order non-symplectic methods. In addition, LAMMPS supports a wide range of interatomic potentials, constraints, diagnostics, software interfaces, and pre- and post-processing features. Additional comments including restrictions and unusual features: This paper serves as the definitive reference for the LAMMPS code.
References
[1]S. Plimpton, Fast parallel algorithms for short-range molecular dynamics. J. Comp. Phys. 117 (1995) 1–19.[2]L. Verlet, Computer experiments on classical fluids: I. Thermodynamical properties of Lennard–Jones molecules, Phys. Rev. 159 (1967) 98–103.}
}

@article{Trinity,
title = {Performance on Trinity Phase 2 (a Cray XC40 utilizing Intel Xeon Phi processors) with Acceptance Applications and Benchmarks.},
author = {Agelastos, Anthony Michael and Rajan, Mahesh and Wichmann, Nathan and Baker, Randy and Domino, Stefan P. and Draeger, Erik W. and Anderson, Sarah and Balma, Jacob and Behling, S. and Berry, Mike and Carrier, Pierre and Davis, Mike and McMahon, Kim and Sandness, D. and Thomas, Kevin and Warren, S. and Zhu, T.},
abstractNote = {Abstract not provided.},
url = {https://www.osti.gov/biblio/1457905},
place = {United States},
year = {2017},
month = {5}
}

@misc{ExaMiniMD,
  author = {Co-design center for Particle Applications},
  title = {ExaMiniMD},
  year = {2017},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/ECP-copa/ExaMiniMD}}
}

@misc{SWFFT,
  author = {Adrian Pope},
  title = {SWFFT},
  year = {2017},
  publisher = {Argonne National Laboratory},
  journal = {GitLab repository},
  howpublished = {\url{https://git.cels.anl.gov/hacc/SWFFT}}
}

@misc{NEKbone,
  author = {Paul Fischer and Katherine Heisey},
  title = {NEKbone},
  year = {2014},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/ECP-copa/ExaMiniMD}}
}
@article{scikit,
  title={Scikit-learn: Machine learning in Python},
  author={Pedregosa, Fabian and Varoquaux, Ga{\"e}l and Gramfort, Alexandre and Michel, Vincent and Thirion, Bertrand and Grisel, Olivier and Blondel, Mathieu and Prettenhofer, Peter and Weiss, Ron and Dubourg, Vincent and others},
  journal={the Journal of machine Learning research},
  volume={12},
  pages={2825--2830},
  year={2011},
  publisher={JMLR. org}
}

@article{SMITH20041007,
title = {Predicting application run times with historical information},
journal = {Journal of Parallel and Distributed Computing},
volume = {64},
number = {9},
pages = {1007-1016},
year = {2004},
issn = {0743-7315},
doi = {https://doi.org/10.1016/j.jpdc.2004.06.008},
url = {https://www.sciencedirect.com/science/article/pii/S0743731504000991},
author = {Warren Smith and Ian Foster and Valerie Taylor},
abstract = {We present a technique for predicting the run times of parallel applications based upon the run times of “similar” applications that have executed in the past. The novel aspect of our work is the use of search techniques to determine those application characteristics that yield the best definition of similarity for the purpose of making predictions. We use four workloads recorded from parallel computers at Argonne National Laboratory, the Cornell Theory Center, and the San Diego Supercomputer Center to evaluate the effectiveness of our approach. We show that on these workloads our techniques achieve predictions that are between 21 and 64 percent better than those achieved by other techniques; our approach achieves mean prediction errors that are between 29 and 59 percent of mean application run times.}
}

@INPROCEEDINGS{5493447,
  author={Matsunaga, Andréa and Fortes, José A.B.},
  booktitle={2010 10th IEEE/ACM International Conference on Cluster, Cloud and Grid Computing}, 
  title={On the Use of Machine Learning to Predict the Time and Resources Consumed by Applications}, 
  year={2010},
  volume={},
  number={},
  pages={495-504},
  abstract={Most data centers, clouds and grids consist of multiple generations of computing systems, each with different performance profiles, posing a challenge to job schedulers in achieving the best usage of the infrastructure. A useful piece of information for scheduling jobs, typically not available, is the extent to which applications will use available resources once they are executed. This paper comparatively assesses the suitability of several machine learning techniques for predicting spatio temporal utilization of resources by applications. Modern machine learning techniques able to handle large number of attributes are used, taking into account application- and system-specific attributes (e.g., CPU micro architecture, size and speed of memory and storage, input data characteristics and input parameters). The work also extends an existing classification tree algorithm, called Predicting Query Runtime (PQR), to the regression problem by allowing the leaves of the tree to select the best regression method for each collection of data on leaves. The new method (PQR2) yields the best average percentage error, predicting execution time, memory and disk consumption for two bioinformatics applications, BLAST and RAxML, deployed on scenarios that differ in system and usage. In specific scenarios where usage is a non-linear function of system and application attributes, certain configurations of two other machine learning algorithms, Support Vector Machine and k-nearest neighbors, also yield competitive results. In addition, experiments show that the inclusion of system performance and application-specific attributes also improves the performance of machine learning algorithms investigated.},
  keywords={},
  doi={10.1109/CCGRID.2010.98},
  ISSN={},
  month={May},}

@InProceedings{Evalix,
author="Emeras, Joseph
and Varrette, S{\'e}bastien
and Guzek, Mateusz
and Bouvry, Pascal",
editor="Desai, Narayan
and Cirne, Walfredo",
title="Evalix: Classification and Prediction of Job Resource Consumption on HPC Platforms",
booktitle="Job Scheduling Strategies for Parallel Processing",
year="2017",
publisher="Springer International Publishing",
address="Cham",
pages="102--122",
abstract="At the advent of a wished (or forced) convergence between High Performance Computing HPC platforms, stand-alone accelerators and virtualized resources from Cloud Computing CC systems, this article unveils the job prediction component of the Evalix project. This framework aims at an improved efficiency of the underlying Resource and Job Management System RJMS within heterogeneous HPC facilities by the automatic evaluation and characterization of the submitted workload. The objective is not only to better adapt the scheduled jobs to the available resource capabilities, but also to reduce the energy costs. For that purpose, we collected the resource consumption of all the jobs executed on a production cluster for a period of three months. Based on the analysis then on the classification of the jobs, we computed a resource consumption model. The objective is to train a set of predictors based on the aforementioned model, that will give the estimated CPU, memory and IO used by the jobs. The analysis of the resource consumption highlighted that different classes of jobs have different kinds of resource needs and the classification of the jobs enabled to characterize several application patterns of the users. We also discovered that several users whose resource usage on the cluster is considered as too low, are responsible for a loss of CPU time on the order of five years over the considered three month period. The predictors, trained from a supervised learning algorithm, were able to correctly classify a large set of data. We evaluated them with three performance indicators that gave an information retrieval rate of 71{\%} to 89{\%} and a probability of accurate prediction between 0.7 and 0.8. The results of this work will be particularly helpful for designing an optimal partitioning of the considered heterogeneous platform, taking into consideration the real application needs and thus leading to energy savings and performance improvements. Moreover, apart from the novelty of the contribution, the accurate classification scheme offers new insights of users behavior of interest for the design of future HPC platforms.",
isbn="978-3-319-61756-5"
}

@INPROCEEDINGS{7776517,  author={McKenna, Ryan and Herbein, Stephen and Moody, Adam and Gamblin, Todd and Taufer, Michela},  booktitle={2016 IEEE International Conference on Cluster Computing (CLUSTER)},   title={Machine Learning Predictions of Runtime and IO Traffic on High-End Clusters},   year={2016},  volume={},  number={},  pages={255-258},  abstract={We use supervised machine learning algorithms (i.e., Decision Trees, Random Forest, and K-nearest Neighbors) to predict performance characteristics such as runtime and IO traffic of batch jobs on high-end clusters, using only user job scripts as input. We show that decision trees outperform other algorithms and accurately predict the runtime of 73\% of jobs within a error tolerance of 10 minutes, which is a 51\% improvement over the user requested runtime.},  keywords={},  doi={10.1109/CLUSTER.2016.58},  ISSN={2168-9253},  month={Sep.},}

@inproceedings{galleguillos2017data,
  title={Data-driven job dispatching in HPC systems},
  author={Galleguillos, Cristian and S{\^\i}rbu, Alina and Kiziltan, Zeynep and Babaoglu, Ozalp and Borghesi, Andrea and Bridi, Thomas},
  booktitle={International Workshop on Machine Learning, Optimization, and Big Data},
  pages={449--461},
  year={2017},
  organization={Springer}
}

@inproceedings{10.1145/3200921.3200937,
author = {Obaida, Mohammad Abu and Liu, Jason and Chennupati, Gopinath and Santhi, Nandakishore and Eidenbenz, Stephan},
title = {Parallel Application Performance Prediction Using Analysis Based Models and HPC Simulations},
year = {2018},
isbn = {9781450350921},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3200921.3200937},
doi = {10.1145/3200921.3200937},
abstract = {Parallel application performance models provide valuable insight about the performance in real systems. Capable tools providing fast, accurate, and comprehensive prediction and evaluation of high-performance computing (HPC) applications and system architectures have important value. This paper presents PyPassT, an analysis based modeling framework built on static program analysis and integrated simulation of the target HPC architectures. More specifically, the framework analyzes application source code written in C with OpenACC directives and transforms it into an application model describing its computation and communication behavior (including CPU and GPU workloads, memory accesses, and message-passing transactions). The application model is then executed on a simulated HPC architecture for performance analysis. Preliminary experiments demonstrate that the proposed framework can represent the runtime behavior of benchmark applications with good accuracy.},
booktitle = {Proceedings of the 2018 ACM SIGSIM Conference on Principles of Advanced Discrete Simulation},
pages = {49–59},
numpages = {11},
keywords = {simulation, performance modeling, performance prediction, high-performance computing, program analysis},
location = {Rome, Italy},
series = {SIGSIM-PADS '18}
}

@INPROCEEDINGS{Omar,  author={Aaziz, Omar and Cook, Jonathan and Tanash, Mohammed},  booktitle={2018 IEEE International Conference on Cluster Computing (CLUSTER)},   title={Modeling Expected Application Runtime for Characterizing and Assessing Job Performance},   year={2018},  volume={},  number={},  pages={543-551},  abstract={In this paper, we present a methodology for modeling the expected runtime of a job based on historical application data and data from the job itself. This estimation model is useful for both for HPC users and administrators as a metric to compare the actual job runtime to, thus establishing a measure of performance of the job. We used job data, system data, and hardware performance counters in a near-zero overhead manner to model and assess job performance, in particular whether or not the job runtime was in line with expectations from historical application performance. We show over three proxy applications and three real applications that our estimations are within 5\% of actual performance.},  keywords={},  doi={10.1109/CLUSTER.2018.00070},  ISSN={2168-9253},  month={Sep.},}

@inproceedings{PRIONN,
author = {Wyatt, Michael R. and Herbein, Stephen and Gamblin, Todd and Moody, Adam and Ahn, Dong H. and Taufer, Michela},
title = {PRIONN: Predicting Runtime and IO Using Neural Networks},
year = {2018},
isbn = {9781450365109},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3225058.3225091},
doi = {10.1145/3225058.3225091},
abstract = {For job allocation decision, current batch schedulers have access to and use only information on the number of nodes and runtime because it is readily available at submission time from user job scripts. User-provided runtimes are typically inaccurate because users overestimate or lack understanding of job resource requirements. Beyond the number of nodes and runtime, other system resources, including IO and network, are not available but play a key role in system performance. There is the need for automatic, general, and scalable tools that provide accurate resource usage information to schedulers so that, by becoming resource-aware, they can better manage system resources.We tackle this need by presenting a tool for Predicting Runtime and IO using Neural Networks (PRIONN). PRIONN automates prediction of per-job runtime and IO resource usage, enabling IO-aware scheduling on HPC systems. The novelty of our tool is the input of whole job scripts into deep learning models that allows complete automation of runtime and IO resource predictions. We demonstrate the power of PRIONN with runtime and IO resource predictions applied to IO-aware scheduling for real HPC data. Specifically, we achieve over 75\% mean and 98\% median accuracy for runtime and IO predictions across 300,000 jobs from a real HPC machine. We combine our per-job runtime and IO predictions with queue and system simulations to predict future system IO usage accurately. We predict over 50\% of IO bursts in advance on a real HPC system.},
booktitle = {Proceedings of the 47th International Conference on Parallel Processing},
articleno = {46},
numpages = {12},
keywords = {IO-Aware Scheduler, Convolutional Neural Network, IO Prediction},
location = {Eugene, OR, USA},
series = {ICPP 2018}
}

@INPROCEEDINGS{8725643,  author={Wang, Qiqi and Li, Jing and Wang, Shuo and Wu, Guibao},  booktitle={2019 IEEE 4th International Conference on Cloud Computing and Big Data Analysis (ICCCBDA)},   title={A Novel Two-Step Job Runtime Estimation Method Based on Input Parameters in HPC System},   year={2019},  volume={},  number={},  pages={311-316},  abstract={Accurate job runtime estimation is one of key parts of scheduling strategy design in high performance computing system. The job characteristics generally contain the execution time and the outer layout parameters such as the consumed processor numbers, the user-estimated execution time and the job ID. Existing researches concentrate on proposing better machine learning methods to achieve accurate job runtime estimation. In this paper, multiple extra job characteristics are introduced to determine job execution pattern, which in turn will help acquire a refined model. Through combining a novel two-step job runtime estimation with a new fusion approach, we get the final job execution time prediction. Experimental results show that our algorithm can improve the accuracy of job runtime estimation up to 18.8\%, and the weighted absolute error is 13.8\% lower than the baseline.},  keywords={},  doi={10.1109/ICCCBDA.2019.8725643},  ISSN={},  month={April},}

@INPROCEEDINGS{9196294,  author={Cheon, Hyunjoon and Ryu, Jinseung and Park, Chan Yeol and Han, Yo-Sub},  booktitle={2020 IEEE International Conference on Autonomic Computing and Self-Organizing Systems Companion (ACSOS-C)},   title={SW Runtime Estimation using Automata Theory and Deep Learning on HPC},   year={2020},  volume={},  number={},  pages={7-12},  abstract={People use high performance computers (HPCs) for computation-intensive tasks. Often these tasks require a lot of running time of their corresponding softwares. It is important to execute several tasks simultaneously for the system utilization while finishing all tasks within their desired deadlines. Therefore, it is important to know the runtime of each computation-intensive task without executing them in order to schedule the tasks on HPC and obtain better system performance. We propose a method for predicting runtime of MPI-based softwares on HPC using automata theory and deep learning. We first analyze a source code of an input program by representing the code as finite automata and measuring their state complexities. Next, we train the execution runtime of each module of our finite automata using deep neural network (DNN) together with its own state complexity. Then we combine all modules and make a single SW-runtime-prediction model. For experiment, we train the proposed model using OSU benchmark data, HPL and two in-house datasets, and present the usefulness of our model. We also demonstrate the adaptability of our model by updating the current model for new inputs using incremental DNN, which is an important feature for coping with new softwares or new systems.},  keywords={},  doi={10.1109/ACSOS-C51401.2020.00021},  ISSN={},  month={Aug},}

@InProceedings{10.1007/978-3-030-48340-1_48,
author="Ozer, Gence
and Garg, Sarthak
and Davoudi, Neda
and Poerwawinata, Gabrielle
and Maiterth, Matthias
and Netti, Alessio
and Tafani, Daniele",
editor="Schwardmann, Ulrich
and Boehme, Christian
and B. Heras, Dora
and Cardellini, Valeria
and Jeannot, Emmanuel
and Salis, Antonio
and Schifanella, Claudio
and Manumachu, Ravi Reddy
and Schwamborn, Dieter
and Ricci, Laura
and Sangyoon, Oh
and Gruber, Thomas
and Antonelli, Laura
and Scott, Stephen L.",
title="Towards a Predictive Energy Model for HPC Runtime Systems Using Supervised Learning",
booktitle="Euro-Par 2019: Parallel Processing Workshops",
year="2020",
publisher="Springer International Publishing",
address="Cham",
pages="626--638",
abstract="High-Performance Computing systems collect vast amounts of operational data with the employment of monitoring frameworks, often augmented with additional information from schedulers and runtime systems. This amount of data can be used and turned into a benefit for operational requirements, rather than being a data pool for post-mortem analysis. This work focuses on deriving a model with supervised learning which enables optimal selection of CPU frequency during the execution of a job, with the objective of minimizing the energy consumption of a HPC system. Our model is trained utilizing sensor data and performance metrics collected with two distinct open-source frameworks for monitoring and runtime optimization. Our results show good prediction of CPU power draw and number of instructions retired on realistic dynamic runtime settings within a relatively low error margin.",
isbn="978-3-030-48340-1"
}
